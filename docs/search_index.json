[["index.html", "R Programming for Statistical Analysis Chapter 1 Welcome", " R Programming for Statistical Analysis Hammed Akande, Jeff Sauer, Abimbola Ogungbire, Tomiyosi Bola 2021-06-23 Chapter 1 Welcome Thanks for your interest in R Programming for statistical analysis. This is a three-day workshop from June 28 to June 30 (4 PM GMT, 11 AM EDT, 8 AM PDT on all days). This workshop aims to expose early-career scientists to coding and basic statistical analysis in R while fostering collaborations and knowledge sharing among participants. Specifically, we hope this workshop will enable young scholars to build expertise in R and make them competitive in global scholarships. This book is intended to serve as a guide to learning R. Good thing is that the book is (and will be) FREE. So, whether you are attending the workshop live or not, you can always consult this book later on for reference. Please feel free to contribute to this open source project if you would want to add or correct the book. You can submit a pull request on Github or send a the corrections (for example, in R Markdown) and we update the book. As this is only for 3days and limited with time, this workshop will only introduce you to basic coding and statistics and by no means exhaustive. For a more detailed analysis, please refer to online resources or contact any of the workshop facilitators to discuss better. "],["installing-rrstudio.html", "Chapter 2 Installing R/RStudio 2.1 To download R 2.2 To download R Studio", " Chapter 2 Installing R/RStudio Installing R and RStudio, Installing and loading Packages Before you start programming in R, you will need to download and install R and RStudio on your computer. R is the programming language used for statistical analysis. R Studio is an Integrated Development Environment (IDE) and a Graphical User Interface (GUI) that allows for easy programming in R. It is important to note that you can use R without RStudio. However, you can not use RStudio without R. So, I encourage you to download both. 2.1 To download R R is hosted on the Comprehensive R Archive Network (CRAN) website (https://cran.r-project.org/). Once you are on the CRAN website, you would see three different links to download R. Please consider your computer operating system and select whichever best describes it. For example, if youre using a Windows computer, please click on R for windows. If this is your first time installing R and you have not used R before, please click on the 1st link you see (base- Install R for the first time); otherwise, update your R (if necessary) or download R Studio (see below for a guide on how to do this). If youre using Mac or Linus, follow the same procedure on the CRAN website to download and install R. Once you successfully install R, then you can download R studio. 2.2 To download R Studio To download R Studio, please visit this website (https://www.rstudio.com/products/rstudio/download/). Once you click on that link, download the R Studio version recommended for your computer and install it. Once you install R Studio, you can open it, and voila- welcome to the world of programming in R. That is all for all now. If you do not get everything now- dont worry, I will run through it again during the workshop. The aim of giving you this early is to fast-track the process. Feel free to ask questions about the installation on slack or during the workshop- I will be glad to answer. "],["data-structure-and-basic-progamming-in-rstudio.html", "Chapter 3 Data Structure and Basic Progamming in RStudio", " Chapter 3 Data Structure and Basic Progamming in RStudio "],["data-visualization.html", "Chapter 4 Data Visualization", " Chapter 4 Data Visualization "],["basic-statistical-analysis.html", "Chapter 5 Basic Statistical Analysis 5.1 Analysis of Variance (ANOVA)", " Chapter 5 Basic Statistical Analysis ANOVA, Correlation and Regression 5.1 Analysis of Variance (ANOVA) 5.1.1 One-Way ANOVA ANOVA is a parametric test and simply an extension of two-samples t-test. By Parametric, I mean it make assumptions regarding the shape of the population. Such assumption includes normal distribution in each factor level, commonly refers to as a bell-shaped curve, homogeneity (equal variance) and that the observations are independent. Basically, in your research or more broadly, statistics, you often hear or conduct one or two way ANOVA. What this means is about the factor in question (the number of predictors/explanatory/independent variables). In one-way ANOVA,you only have one independent (factor) variable and in a two-way ANOVA, you have two. We shall see examples below. When conducting ANOVA, you need to set up hypothesis. Basically, you have either H0 (null) or HA(Alternate hypothesis). Usually, your H0 hypothesis implies there is no difference in the mean of your groups. Simply put, your observations comes from populations with the same variance (homoscedastic). HA on the other hand states there is a difference (heteroscedastic). To test for this assumption of homoscedasticity, you can use the Levenes test (see below). N.B: if your H0 is rejected, you should not proceed with the standard ANOVA test- perhaps consider the equivalent non-parametric test (e.g., Kruskal-Wallis test) Ideally, you should state this out explicitly, such as below: #H0: there is no mean difference in the observation under consideration #HA: there is a significant difference. Enough of lecture, lets quickly demonstrate this with data We shall be using the Circadian data. So, loading the data. For quick context, the data is about jet lag and adjusting to a different time zone. Campbell and Murphy (1998) claimed people adjust to their new time zone once the light reset their internal, circadian clock. Wright and Czeisler 2002 revisited this study and measured the circadian rhythm of melatonin production. They subjected 22 people to random treatments; control, knees only and eyes. Please read more on this paper online or attached pdf (Wright and Czeisler 2002). So for our analysis, we want to compare phase shifts in the circadian rhytm of melatonin productions in participants given another light treatments.  Load data Circadian &lt;- read.csv(file.choose()) # Load the csv named &quot;Circadian&quot; # Let&#39;s check what&#39;s in our data View(Circadian) # or use the &quot;dplyr&quot; package to randomly print 10 observations library(dplyr) dplyr::sample_n(Circadian, 10) ## treatment shift ## 1 knee -1.61 ## 2 eyes -1.48 ## 3 knee -0.96 ## 4 control 0.20 ## 5 knee 0.31 ## 6 knee 0.03 ## 7 control -0.60 ## 8 control -0.37 ## 9 eyes -1.52 ## 10 control -0.64 As you can see, this is a one-way factorial design. It has only one factor (the column treatment). Different treatments represents the levels in that factor and ideally are always ordered alphabetically. If you want to check the levels in your data, you can use the code below levels(Circadian$treatment) ## NULL # See it gives error right? You need to order them Circadian$treatment = ordered(Circadian$treatment, levels = c(&quot;control&quot;,&quot;eyes&quot;, &quot;knee&quot;)) # Check your levels now levels(Circadian$treatment) ## [1] &quot;control&quot; &quot;eyes&quot; &quot;knee&quot; Before we proceed with normal ANOVA calculation, lets play arond with codes and calculate the mean, median and standard deviation for this data. group_by(Circadian, treatment) %&gt;% summarise( count = n(), mean = mean(shift, na.rm = TRUE), sd = sd(shift, na.rm = TRUE) ) ## # A tibble: 3 x 4 ## treatment count mean sd ## &lt;ord&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 control 8 -0.309 0.618 ## 2 eyes 7 -1.55 0.706 ## 3 knee 7 -0.336 0.791 Also, you may want to even visualize this data and see how it looks. Lets install a package called ggpubr (which is from ggplot2 and used for publications mostly, hence the name ggpubr) if(!require(ggpubr)) {install.packages(&quot;ggpubr&quot;); library(ggpubr)} ggboxplot(Circadian, x = &quot;treatment&quot;, y = &quot;shift&quot;, color = &quot;treatment&quot;, palette = c(&quot;#00AFBB&quot;, &quot;#E7B800&quot;, &quot;#FC4E07&quot;), order = c(&quot;control&quot;, &quot;eyes&quot;, &quot;knee&quot;), ylab = &quot;Shift&quot;, xlab = &quot;Treatment&quot;) Now lets check our one-way ANOVA. ANOVA TEST Circadian_anova &lt;- lm( shift ~ treatment, data=Circadian) anova(Circadian_anova) ## Analysis of Variance Table ## ## Response: shift ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## treatment 2 7.2245 3.6122 7.2894 0.004472 ** ## Residuals 19 9.4153 0.4955 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Another method to calculate ANOVA using the aov function Circadian.aov &lt;- aov(shift ~ treatment, data = Circadian) summary(Circadian.aov) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## treatment 2 7.224 3.612 7.289 0.00447 ** ## Residuals 19 9.415 0.496 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Still the same as above, right? Good. It is important to check all assumptions. So, we need to check all assumptions of ANOVA here now. This is important to confirm the validity of our statistical tool. Test for homogeneity plot(Circadian_anova, 1) leveneTest(shift ~ factor(treatment), data=Circadian) ## Levene&#39;s Test for Homogeneity of Variance (center = median) ## Df F value Pr(&gt;F) ## group 2 0.1586 0.8545 ## 19 # If you run this directly, you shold get error message (unless you have installed the package containing the &quot;levene&quot;) install.packages(c(&quot;openxlsx&quot;, &quot;car&quot;, dependecies=TRUE)) ## Error in install.packages : Updating loaded packages library(car) #Now run your levene test leveneTest(shift ~ factor(treatment), data=Circadian) # see that the P value is &gt; 0.05, there is no evidence to reject the H0 (they have the same variance) ## Levene&#39;s Test for Homogeneity of Variance (center = median) ## Df F value Pr(&gt;F) ## group 2 0.1586 0.8545 ## 19 Test for Normality plot(Circadian_anova, which=2) # This normality assumption can be further confirmed using the Shapiro normality test. circadian_residuals &lt;- residuals(object = Circadian_anova) shapiro.test(circadian_residuals) ## ## Shapiro-Wilk normality test ## ## data: circadian_residuals ## W = 0.95893, p-value = 0.468 # From the Shapiro normality test, the P-value = 0.468, which is greater than the chosen P-value (0.05) and therefore, we have strong evidence to conclude that this data comes from a normal population, as such normality assumption is met. Lastly, Since the ANOVA test is significant, you may want to compute the Tukey test to check for pairwise-comparison between the means of groups # Compute the ANOVA TukeyHSD(Circadian.aov) # Turkey will not accept anova generated from &quot;lm&quot; function. So use the aov here. ## Tukey multiple comparisons of means ## 95% family-wise confidence level ## ## Fit: aov(formula = shift ~ treatment, data = Circadian) ## ## $treatment ## diff lwr upr p adj ## eyes-control -1.24267857 -2.1682364 -0.3171207 0.0078656 ## knee-control -0.02696429 -0.9525222 0.8985936 0.9969851 ## knee-eyes 1.21571429 0.2598022 2.1716263 0.0116776 # You can see that both eyes-control and knee-eyes are both significant (check the p-value) Also, maybe you try the Pairwise-test (not compulsory though) Pairwise t-test This can be used to compute pairwise comparisons between group levels with corrections for multiple testing. pairwise.t.test(Circadian$shift, Circadian$treatment, p.adjust.method = &quot;BH&quot;) ## ## Pairwise comparisons using t tests with pooled SD ## ## data: Circadian$shift and Circadian$treatment ## ## control eyes ## eyes 0.0066 - ## knee 0.9418 0.0066 ## ## P value adjustment method: BH # The BH means that- adjust the p-values by the Benjamini-Hochberg method. 5.1.2 TWO-Way ANOVA Here, lets use fictional study, obviously, you could use your own data if you have. Fictional Study from (Hammed Akande). Context- Sclerophrys perreti is an endemic species to Nigeria, reportedly lost for over 50 years and rediscovered in 2013 at its type locality. It is considered to be a vulnerable species facing an extinction risk due to several threats, including predators, among other factors. The presence of predators in the habitats of Sclerophrys perreti poses a threat to the survival of this species. In this study, the aim is to check whether Sclerophrys perreti can survive in the presence or absence of predators and assess if this can be explained by the behavior of this predator species (day or night). This experiment involves monitoring the activities of Sclerophrys perreti in the habitat for three months during the rainy season. Hypothetically, we would expect that the survival of Sclerophrys perreti depends on the abundance of predators (presence or absence) in the neighboring environment, survey time (day or night) and to investigate if there is an interaction between the predictors (predator and survey time) on the abundance of Sclerophrys perreti Perret = read.csv(file.choose(), header = TRUE) # Load the csv file named &quot;AkandeData&quot; # ANOVA TEST Perret_anova &lt;- lm( Call ~ Predator*Survey, data=Perret) anova(Perret_anova) ## Analysis of Variance Table ## ## Response: Call ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Predator 1 17.6487 17.6487 14.8758 0.001395 ** ## Survey 1 3.1539 3.1539 2.6584 0.122528 ## Predator:Survey 1 5.8835 5.8835 4.9591 0.040664 * ## Residuals 16 18.9824 1.1864 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Test for homogeneity plot(Perret_anova, 1) leveneTest(Call ~ factor(Predator) * factor(Survey), data=Perret) ## Levene&#39;s Test for Homogeneity of Variance (center = median) ## Df F value Pr(&gt;F) ## group 3 1.687 0.2098 ## 16 # From the result of the &quot;levene test&quot;, given that the P-value is = 0.2098, which is greater than the chosen P-value of 0.05, we have strong evidence to accept the null hypothesis and conclude there&#39;s no evidence that all the treatment combination come from population with different variance. Therefore, the assumption of homogeneity is met. Assessing normality plot(Perret_anova, which=2) # This normality assumption can be further confirmed using the Shapiro normality test. anova_residuals &lt;- residuals(object = Perret_anova) shapiro.test(anova_residuals) ## ## Shapiro-Wilk normality test ## ## data: anova_residuals ## W = 0.95544, p-value = 0.4573 # As it can be observed from the QQ plot, most of the residuals falls on the straight line and implies that this data comes from a normally distributed population. This can be further confirmed using the Shapiro-Wilk normality test. From the Shapiro normality test, the P-value = 0.4573, which is greater than the chosen P-value (0.05) and therefore, we have strong evidence to conclude that this data comes from a normal population, as such normality assumption is met. # Interaction plot Perret_summary &lt;- Perret %&gt;% group_by(Survey, Predator) %&gt;% summarise(y_mean = mean(Call), y_se = psych::describe(Call)$se) ## `summarise()` has grouped output by &#39;Survey&#39;. You can override using the `.groups` argument. Perret_summary ## # A tibble: 4 x 4 ## # Groups: Survey [2] ## Survey Predator y_mean y_se ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 day &quot;Absence &quot; 4.35 0.683 ## 2 day &quot;Presence&quot; 3.3 0.256 ## 3 night &quot;Absence &quot; 6.54 1.04 ## 4 night &quot;Presence&quot; 3.22 0.212 Perret_summary%&gt;% ggplot(aes(x = Survey, y = y_mean, color = Predator)) + geom_line(aes(group = Predator)) + geom_point() + geom_errorbar(aes(ymin = y_mean-1.96*y_se, ymax = y_mean+1.96*y_se), width = .1) + labs(x = &quot;Survey Time&quot;,color = &quot;Predator&quot;, y = &quot;Activity Call (min)&quot;) + theme_classic() ``` "],["species-distribution-modeling.html", "Chapter 6 Species Distribution Modeling", " Chapter 6 Species Distribution Modeling "],["resources-and-references.html", "Chapter 7 Resources and References", " Chapter 7 Resources and References "]]
